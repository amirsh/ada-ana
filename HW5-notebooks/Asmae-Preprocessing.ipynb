{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "## Data investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from wordcloud import WordCloud\u001c",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# filenames\n",
    "Aliases_filename =os.path.join('hillary-clinton-emails','Aliases.csv') \n",
    "Emails_filename =os.path.join('hillary-clinton-emails','Emails.csv') \n",
    "EmailReceivers_filename =os.path.join('hillary-clinton-emails','EmailReceivers.csv') \n",
    "Persons_filename =os.path.join('hillary-clinton-emails','Persons.csv') \n",
    "Hashes_filename =os.path.join('hillary-clinton-emails','hashes.txt') \n",
    "\n",
    "# Data importing\n",
    "Aliases = pd.read_csv(Aliases_filename, index_col = 0, header = 0)\n",
    "Emails = pd.read_csv(Emails_filename , index_col = 0, header = 0)\n",
    "EmailReceivers = pd.read_csv(EmailReceivers_filename , index_col = 0, header = 0)\n",
    "Persons = pd.read_csv(Persons_filename, index_col = 0, header = 0)\n",
    "Hashes = open(Hashes_filename).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alias</th>\n",
       "      <th>PersonId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111th congress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agna usemb kabul afghanistan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ap</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asuncion</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alec</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Alias  PersonId\n",
       "Id                                        \n",
       "1                 111th congress         1\n",
       "2   agna usemb kabul afghanistan         2\n",
       "3                             ap         3\n",
       "4                       asuncion         4\n",
       "5                           alec         5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Aliases.shape)\n",
    "Aliases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7945, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocNumber</th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataTo</th>\n",
       "      <th>MetadataFrom</th>\n",
       "      <th>SenderPersonId</th>\n",
       "      <th>MetadataDateSent</th>\n",
       "      <th>MetadataDateReleased</th>\n",
       "      <th>MetadataPdfLink</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C05739545</td>\n",
       "      <td>WOW</td>\n",
       "      <td>H</td>\n",
       "      <td>Sullivan, Jacob J</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C05739546</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-03T05:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C05739547</td>\n",
       "      <td>CHRIS STEVENS</td>\n",
       "      <td>;H</td>\n",
       "      <td>Mills, Cheryl D</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739547...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C05739550</td>\n",
       "      <td>CAIRO CONDEMNATION - FINAL</td>\n",
       "      <td>H</td>\n",
       "      <td>Mills, Cheryl D</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739550...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C05739554</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>Abedin, Huma</td>\n",
       "      <td>H</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2011-03-11T05:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739554...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DocNumber                                    MetadataSubject  \\\n",
       "Id                                                                 \n",
       "1   C05739545                                                WOW   \n",
       "2   C05739546  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "3   C05739547                                      CHRIS STEVENS   \n",
       "4   C05739550                         CAIRO CONDEMNATION - FINAL   \n",
       "5   C05739554  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "\n",
       "      MetadataTo       MetadataFrom  SenderPersonId  \\\n",
       "Id                                                    \n",
       "1              H  Sullivan, Jacob J            87.0   \n",
       "2              H                NaN             NaN   \n",
       "3             ;H    Mills, Cheryl D            32.0   \n",
       "4              H    Mills, Cheryl D            32.0   \n",
       "5   Abedin, Huma                  H            80.0   \n",
       "\n",
       "             MetadataDateSent       MetadataDateReleased  \\\n",
       "Id                                                         \n",
       "1   2012-09-12T04:00:00+00:00  2015-05-22T04:00:00+00:00   \n",
       "2   2011-03-03T05:00:00+00:00  2015-05-22T04:00:00+00:00   \n",
       "3   2012-09-12T04:00:00+00:00  2015-05-22T04:00:00+00:00   \n",
       "4   2012-09-12T04:00:00+00:00  2015-05-22T04:00:00+00:00   \n",
       "5   2011-03-11T05:00:00+00:00  2015-05-22T04:00:00+00:00   \n",
       "\n",
       "                                      MetadataPdfLink  \n",
       "Id                                                     \n",
       "1   DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...  \n",
       "2   DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...  \n",
       "3   DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739547...  \n",
       "4   DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739550...  \n",
       "5   DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739554...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Emails.shape)\n",
    "Emails.ix[:,0:8].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MetadataCaseNumber</th>\n",
       "      <th>MetadataDocumentClass</th>\n",
       "      <th>ExtractedSubject</th>\n",
       "      <th>ExtractedTo</th>\n",
       "      <th>ExtractedFrom</th>\n",
       "      <th>ExtractedCc</th>\n",
       "      <th>ExtractedDateSent</th>\n",
       "      <th>ExtractedCaseNumber</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>FW: Wow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sullivan, Jacob J &lt;Sullivan11@state.gov&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday, September 12, 2012 10:16 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-2015-04841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>Re: Chris Stevens</td>\n",
       "      <td>B6</td>\n",
       "      <td>Mills, Cheryl D &lt;MillsCD@state.gov&gt;</td>\n",
       "      <td>Abedin, Huma</td>\n",
       "      <td>Wednesday, September 12, 2012 11:52 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>FVV: Cairo Condemnation - Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mills, Cheryl D &lt;MillsCD@state.gov&gt;</td>\n",
       "      <td>Mitchell, Andrew B</td>\n",
       "      <td>Wednesday, September 12,2012 12:44 PM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-2015-04841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MetadataCaseNumber MetadataDocumentClass                 ExtractedSubject  \\\n",
       "Id                                                                             \n",
       "1        F-2015-04841         HRC_Email_296                          FW: Wow   \n",
       "2        F-2015-04841         HRC_Email_296                              NaN   \n",
       "3        F-2015-04841         HRC_Email_296                Re: Chris Stevens   \n",
       "4        F-2015-04841         HRC_Email_296  FVV: Cairo Condemnation - Final   \n",
       "5        F-2015-04841         HRC_Email_296                              NaN   \n",
       "\n",
       "   ExtractedTo                             ExtractedFrom         ExtractedCc  \\\n",
       "Id                                                                             \n",
       "1          NaN  Sullivan, Jacob J <Sullivan11@state.gov>                 NaN   \n",
       "2          NaN                                       NaN                 NaN   \n",
       "3           B6       Mills, Cheryl D <MillsCD@state.gov>        Abedin, Huma   \n",
       "4          NaN       Mills, Cheryl D <MillsCD@state.gov>  Mitchell, Andrew B   \n",
       "5          NaN                                       NaN                 NaN   \n",
       "\n",
       "                         ExtractedDateSent ExtractedCaseNumber  \n",
       "Id                                                              \n",
       "1   Wednesday, September 12, 2012 10:16 AM        F-2015-04841  \n",
       "2                                      NaN        F-2015-04841  \n",
       "3   Wednesday, September 12, 2012 11:52 AM        F-2015-04841  \n",
       "4    Wednesday, September 12,2012 12:44 PM        F-2015-04841  \n",
       "5                                      NaN        F-2015-04841  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emails.ix[:,8:16].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExtractedDocNumber</th>\n",
       "      <th>ExtractedDateReleased</th>\n",
       "      <th>ExtractedReleaseInPartOrFull</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C05739545</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C05739546</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C05739547</td>\n",
       "      <td>05/14/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>Thx</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C05739550</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C05739554</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\nFriday, March 11,...</td>\n",
       "      <td>B6\\nUNCLASSIFIED\\nU.S. Department of State\\nCa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExtractedDocNumber ExtractedDateReleased ExtractedReleaseInPartOrFull  \\\n",
       "Id                                                                         \n",
       "1           C05739545            05/13/2015              RELEASE IN FULL   \n",
       "2           C05739546            05/13/2015              RELEASE IN PART   \n",
       "3           C05739547            05/14/2015              RELEASE IN PART   \n",
       "4           C05739550            05/13/2015              RELEASE IN PART   \n",
       "5           C05739554            05/13/2015              RELEASE IN PART   \n",
       "\n",
       "                                    ExtractedBodyText  \\\n",
       "Id                                                      \n",
       "1                                                 NaN   \n",
       "2   B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...   \n",
       "3                                                 Thx   \n",
       "4                                                 NaN   \n",
       "5   H <hrod17@clintonemail.com>\\nFriday, March 11,...   \n",
       "\n",
       "                                              RawText  \n",
       "Id                                                     \n",
       "1   UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "2   UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "3   UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "4   UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "5   B6\\nUNCLASSIFIED\\nU.S. Department of State\\nCa...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emails.ix[:,16:22].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DocNumber', 'MetadataSubject', 'MetadataTo', 'MetadataFrom',\n",
       "       'SenderPersonId', 'MetadataDateSent', 'MetadataDateReleased',\n",
       "       'MetadataPdfLink', 'MetadataCaseNumber', 'MetadataDocumentClass',\n",
       "       'ExtractedSubject', 'ExtractedTo', 'ExtractedFrom', 'ExtractedCc',\n",
       "       'ExtractedDateSent', 'ExtractedCaseNumber', 'ExtractedDocNumber',\n",
       "       'ExtractedDateReleased', 'ExtractedReleaseInPartOrFull',\n",
       "       'ExtractedBodyText', 'RawText'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emails.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9306, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmailId</th>\n",
       "      <th>PersonId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EmailId  PersonId\n",
       "Id                   \n",
       "1         1        80\n",
       "2         2        80\n",
       "3         3       228\n",
       "4         3        80\n",
       "5         4        80"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(EmailReceivers.shape)\n",
    "EmailReceivers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111th Congress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGNA USEMB Kabul Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUNCION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name\n",
       "Id                              \n",
       "1                 111th Congress\n",
       "2   AGNA USEMB Kabul Afghanistan\n",
       "3                             AP\n",
       "4                       ASUNCION\n",
       "5                           Alec"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Persons.shape)\n",
    "Persons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current git commit:\\nb7bbe29f3fb9e6c300824308b3139afa433e96a5\\n\\nCurrent ouput md5 hashes:\\nMD5 (output/Aliases.csv) = f8a57f482023e54865a5ffb95921c2c7\\nMD5 (output/EmailReceivers.csv) = 349e5a27ec2ea974451a3fff1bdd1bc9\\nMD5 (output/Emails.csv) = e91226f2d61c72d92d4a0a303b8f7a1c\\nMD5 (output/Persons.csv) = e058a8acf53b74630225878270b5393b\\nMD5 (output/database.sqlite) = d62448386bc43dde3f8df46936a26713\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "\n",
    "Generate a word cloud based on the raw corpus -- using the Python word_cloud library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "1                                                FW: Wow \n",
       "2        B6\\nThursday, March 3, 2011 9:45 PM\\nH: Lates...\n",
       "3                                   Re: Chris Stevens Thx\n",
       "4                        FVV: Cairo Condemnation - Final \n",
       "5        H <hrod17@clintonemail.com>\\nFriday, March 11...\n",
       "6       Meet The Right Wing Extremist Behind Anti-Musl...\n",
       "7       FW: Anti-Muslim film director in hiding, follo...\n",
       "8        H <hrod17@clintonemail.corn>\\nFriday, March 1...\n",
       "9                            FVV: Secretary's remarks FYI\n",
       "10      more on Libya B6\\nWednesday, September 12, 201...\n",
       "11      AbZ and Hb3 on Libya and West Bank/Gaza Fyi\\nB...\n",
       "12       B6\\nWednesday, September 12, 2012 6:16 PM\\nFw...\n",
       "13                                                hey Fyi\n",
       "14       Anne-Marie Slaughter\\nSunday, March 13, 2011 ...\n",
       "15      RE: Not a dry eye in NEA _ .....\\nFrom Randolp...\n",
       "16       I asked to attend your svtc today with Embass...\n",
       "17      Fw: The Youth of Libya Hope. See picture below...\n",
       "18                      Fw: One More Photo Another photo.\n",
       "19                              Fw: S today This is nice.\n",
       "20       Amazing.\\nSullivan, Jacob J <Sullivanii@state...\n",
       "21      Fwd: more on libya H <hrod17@clintonernaii.com...\n",
       "22      Fwd: more on libya Pis print.\\nH < hrod17@clin...\n",
       "23      Fw: H: Magariaf on attack on US in Libya. Sid ...\n",
       "24      Fw: H: Magariaf on attack on US in Libya. Sid ...\n",
       "25                              Re: Proposed Quad Deal B5\n",
       "26       Sidney Blumenthal\\nThursday, September 13, 20...\n",
       "27                        Re: Fwd: more on libya Will do.\n",
       "28                   Fw: Amb Stevens Remind me to discuss\n",
       "29      CNN Belief Biog. Prothero http://religion.b1og...\n",
       "30               Fw: chris Stevens mission See note below\n",
       "                              ...                        \n",
       "7916     sbwhoeop\\nTuesday, December 14, 2010 9:35 AM\\...\n",
       "7917    FW: Remarks of the Spokesman of the Islamic Em...\n",
       "7918                                               Nides \n",
       "7919                                                 Fw: \n",
       "7920    Fw: Norwegian Agency for Development Cooperati...\n",
       "7921    Re: Friday That was what lona had when she wen...\n",
       "7922             Fw: #1 Social Media campaign of 2010 Fyi\n",
       "7923    A new draft of the town hall speech Madame Sec...\n",
       "7924    RE: A new draft of the town hall speech It's a...\n",
       "7925    Speech this morning I will be at a USGLC break...\n",
       "7926    tax bill Passed the Senate 81 to 19. START vot...\n",
       "7927           FW: Matt Lee's piece with write-through -^\n",
       "7928    FW: she is simply a rock star Traffic below fr...\n",
       "7929                    Fwd: Re BB fyi\\nForwarded message\n",
       "7930    FW: Bill Burke White Agree â€” he did all the wr...\n",
       "7931    FW: thanks again Nice\\nForgot to tell you abou...\n",
       "7932                      FW: EU Stopped EURO 47 Million \n",
       "7933                     Fw: more wikithink Worth a read.\n",
       "7934    H: Jamie Rubin finally lands. Sid The unsigned...\n",
       "7935    Fw: (AP) Germany: pullout from Afghanistan to ...\n",
       "7936    Fw: (AP) Palestinians seek state recognition i...\n",
       "7937     Mills, Cheryl D <MillsCD@state.gov>\\nThursday...\n",
       "7938    FW: The Envoy THE NBC/YORKER\\nDecember 14, 201...\n",
       "7939    update Hi. Sorry I haven't had a chance to see...\n",
       "7940    Fwd: FW: Richard (TNR) B6\\nI assume you saw th...\n",
       "7941                                           Fw: Wyden \n",
       "7942    Senate Big change of plans in the Senate. Sena...\n",
       "7943                          Re: Fwd: FW: Richard (TNR) \n",
       "7944     PVerveer B6\\nFriday, December 17, 2010 12:12 ...\n",
       "7945            FW: Note for Secretary Clinton See below.\n",
       "Name: ExtractedSubject, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_t_s = Emails['ExtractedSubject'].str.cat(Emails['ExtractedBodyText'],sep=' ',na_rep='')\n",
    "emails_t_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = emails_t_s.str.cat(sep=' ')\n",
    "wordcloud = WordCloud().generate(text)\n",
    "image = wordcloud.to_image()\n",
    "image.show()\n",
    "#plt.imshow(image)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of nltk (already available in Anaconda environment), implement a standard text pre-processing pipeline (e.g., tokenization, stopword removal, stemming, etc.) and generate a new word cloud. Discuss briefly the pros and cons (if any) of the two word clouds you generated.\n",
    "### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " '<',\n",
       " 'hrod17',\n",
       " '@',\n",
       " 'clintonemail.corn',\n",
       " '>',\n",
       " 'Friday',\n",
       " ',',\n",
       " 'March',\n",
       " '11',\n",
       " ',',\n",
       " '2011',\n",
       " '1:36',\n",
       " 'PM',\n",
       " 'Huma',\n",
       " 'Abedin',\n",
       " 'Fw',\n",
       " ':',\n",
       " 'H',\n",
       " ':',\n",
       " 'Latest',\n",
       " ':',\n",
       " 'How',\n",
       " 'Syria',\n",
       " 'is',\n",
       " 'aiding',\n",
       " 'Qaddafi',\n",
       " 'and',\n",
       " 'more',\n",
       " '...',\n",
       " 'Sid',\n",
       " 'hrc',\n",
       " 'memo',\n",
       " 'Syria',\n",
       " 'aiding',\n",
       " 'libya',\n",
       " '030311.docx',\n",
       " 'Pis',\n",
       " 'print',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = emails_t_s[8]\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stop-words and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'has',\n",
       " 'hasn',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " 'she',\n",
       " 'should',\n",
       " 'shouldn',\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " 'wouldn',\n",
       " 'y',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopset = set(stopwords.words('english'))\n",
    "stopset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '>',\n",
       " 'Friday',\n",
       " ',',\n",
       " 'March',\n",
       " '11',\n",
       " ',',\n",
       " '2011',\n",
       " '1:36',\n",
       " 'PM',\n",
       " 'Huma',\n",
       " 'Abedin',\n",
       " 'Fw',\n",
       " ':',\n",
       " 'H',\n",
       " ':',\n",
       " 'Latest',\n",
       " ':',\n",
       " 'How',\n",
       " 'Syria',\n",
       " 'is',\n",
       " 'aiding',\n",
       " 'Qaddafi',\n",
       " 'and',\n",
       " 'more',\n",
       " '...',\n",
       " 'Sid',\n",
       " 'hrc',\n",
       " 'memo',\n",
       " 'Syria',\n",
       " 'aiding',\n",
       " 'libya',\n",
       " '030311.docx',\n",
       " 'Pis',\n",
       " 'print',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in np.arange(len(tokens)):\n",
    "    if tokens[i] == '<':\n",
    "        while not tokens[i] == '>':\n",
    "            tokens[i]=''\n",
    "            i = i+1\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopset.update(['fw','am','pm','fvv','fwd','re','monday','tuesday',\n",
    "                'wednesday','thursday','friday','saturday','sunday','january','february',\n",
    "               'march','april','may','june','jully','august',\n",
    "               'september','october','november','december'])\n",
    "clean_tokens = []\n",
    "puncts=['.',':','!','?','-','_','\\'','``']\n",
    "\n",
    "for token in tokens:\n",
    "     if token.lower() not in stopset:\n",
    "            word = token\n",
    "            for sym in puncts:\n",
    "                word= word.replace(sym,'')\n",
    "            if len(word)>1:\n",
    "                clean_tokens.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11',\n",
       " '2011',\n",
       " '136',\n",
       " 'Huma',\n",
       " 'Abedin',\n",
       " 'Latest',\n",
       " 'Syria',\n",
       " 'aiding',\n",
       " 'Qaddafi',\n",
       " 'Sid',\n",
       " 'hrc',\n",
       " 'memo',\n",
       " 'Syria',\n",
       " 'aiding',\n",
       " 'libya',\n",
       " '030311docx',\n",
       " 'Pis',\n",
       " 'print']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [wordnet_lemmatizer.lemmatize(token) for token in clean_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11',\n",
       " '2011',\n",
       " '136',\n",
       " 'Huma',\n",
       " 'Abedin',\n",
       " 'Latest',\n",
       " 'Syria',\n",
       " 'aiding',\n",
       " 'Qaddafi',\n",
       " 'Sid',\n",
       " 'hrc',\n",
       " 'memo',\n",
       " 'Syria',\n",
       " 'aiding',\n",
       " 'libya',\n",
       " '030311docx',\n",
       " 'Pis',\n",
       " 'print']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "stemmed_tokens = [porter_stemmer.stem(token).lower() for token in lemmatized_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11',\n",
       " '2011',\n",
       " '136',\n",
       " 'huma',\n",
       " 'abedin',\n",
       " 'latest',\n",
       " 'syria',\n",
       " 'aid',\n",
       " 'qaddafi',\n",
       " 'sid',\n",
       " 'hrc',\n",
       " 'memo',\n",
       " 'syria',\n",
       " 'aid',\n",
       " 'libya',\n",
       " '030311docx',\n",
       " 'pi',\n",
       " 'print']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-process all emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(text,stopset,puncts,wordnet_lemmatizer,porter_stemmer):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "         if token.lower() not in stopset:\n",
    "            word = token\n",
    "            for sym in puncts:\n",
    "                word= word.replace(sym,'')\n",
    "            if len(word)>1:\n",
    "                clean_tokens.append(word)\n",
    "    lemmatized_tokens = [wordnet_lemmatizer.lemmatize(token) for token in clean_tokens]\n",
    "    stemmed_tokens = [porter_stemmer.stem(token).lower() for token in lemmatized_tokens]\n",
    "    clean_text = ' '.join(stemmed_tokens)\n",
    "    return clean_text\n",
    "    \n",
    "stopset = set(stopwords.words('english'))\n",
    "stopset.update(['fw','am','pm','fvv','fwd','re','b6','clintonemail.com','hrod17',\n",
    "                'clintonemail.corn','monday','tuesday',\n",
    "                'wednesday','thursday','friday','saturday','sunday','january','february',\n",
    "               'march','april','may','june','jully','august',\n",
    "               'september','october','november','december'])\n",
    "puncts=['.',':','!','?','-','_','\\'','``']\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "porter_stemmer = PorterStemmer()    \n",
    "\n",
    "clean_emails = [preprocess(emails_t_s[i+1],stopset,puncts,wordnet_lemmatizer,porter_stemmer) for i in np.arange(len(emails_t_s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_emails_df = pd.DataFrame(clean_emails)\n",
    "filename = 'preprocessed_emails.csv'\n",
    "clean_emails_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011 945 latest syria aid qaddafi sid hrc memo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chri steven thx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cairo condemn final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11 2011 136 huma abedin latest syria aid qadda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                                wow\n",
       "1  2011 945 latest syria aid qaddafi sid hrc memo...\n",
       "2                                    chri steven thx\n",
       "3                                cairo condemn final\n",
       "4  11 2011 136 huma abedin latest syria aid qadda..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_emails_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New world cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = ' '.join(clean_emails)\n",
    "wordcloud = WordCloud().generate(text)\n",
    "image = wordcloud.to_image()\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file = open(\"preprocessed_emails.txt\", \"w\")\n",
    "text_file.write(text)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
